{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MSDS 434 Pytorch Final Project Model\n",
        "Notebook processes training data, and runs predictions on given dataset, and uploads predictions to S3 bucket. Upload triggers AWS lambda function, which combines all csvs in bucket and stores in seperate bucket, which will subsequently be used for visualizations in Tableau\n"
      ],
      "metadata": {
        "id": "f9c25uMVADO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install boto3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import boto3\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from botocore.exceptions import ClientError\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "v5tm1kKt_xOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df33a3c-7a6a-4471-8fb7-fd708648c5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.29.3-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.33.0,>=1.32.3 (from boto3)\n",
            "  Downloading botocore-1.32.3-py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.3->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.3->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.0,>=1.32.3->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.29.3 botocore-1.32.3 jmespath-1.0.1 s3transfer-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training dataset\n",
        "\n",
        "train_url = 'https://bankmarketingkt.s3.us-west-2.amazonaws.com/train/train_df.csv'\n",
        "df = pd.read_csv(train_url)\n",
        "\n",
        "# Assuming 'target_column' is the column you want to predict\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "# Encode target labels if they are categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "YkT0J1x-Xpp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer2(out)\n",
        "        return out\n",
        "\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 64\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Learning Rate\n",
        "\n",
        "num_epochs = 100  # Number of Epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
        "    print(f'Test Accuracy: {np.round(accuracy * 100, decimals=2)}%')"
      ],
      "metadata": {
        "id": "WhCj0XnvYgQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21b5aa3-e14a-4fc5-e479-3b7a2ec321bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 95.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new data for prediction\n",
        "\n",
        "predict_csv = '6'\n",
        "new_data_url = f'https://bankmarketingkt.s3.us-west-2.amazonaws.com/predictions/predict_df_{predict_csv}.csv'\n",
        "new_data = pd.read_csv(new_data_url)\n",
        "new_data = new_data.drop('y', axis=1)\n",
        "\n",
        "# Convert new_data to PyTorch tensor\n",
        "\n",
        "new_data_tensor = torch.tensor(new_data.values, dtype=torch.float32)\n",
        "\n",
        "# Ensure your model is in evaluation mode\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Make predictions using the PyTorch model\n",
        "\n",
        "with torch.no_grad():\n",
        "    new_predictions = model(new_data_tensor)\n",
        "\n",
        "_, predicted_classes = torch.max(new_predictions, 1)\n",
        "predicted_classes = predicted_classes.numpy()\n",
        "\n",
        "# Add the predicted values to the dataset\n",
        "\n",
        "new_data['Predicted_y'] = predicted_classes\n",
        "\n",
        "# Create a CSV of the dataset with predictions\n",
        "\n",
        "new_data.to_csv(f'predict_df_{predict_csv}_convert.csv', index=False)\n",
        "\n",
        "# Upload csv to bankmarketingktconverts S3 bucket\n",
        "\n",
        "client = boto3.client('s3',\n",
        "                      aws_access_key_id = userdata.get('AWS_KEY_ID'),\n",
        "                      aws_secret_access_key = userdata.get('AWS_SECRET_ID'))\n",
        "bucket = 'bankmarketingktconverts'\n",
        "cur_path = os.getcwd()\n",
        "filename = os.path.join(cur_path, f'predict_df_{predict_csv}_convert.csv')\n",
        "\n",
        "data = open(filename, 'rb')\n",
        "\n",
        "client.upload_file(filename, bucket, f'predict_df_{predict_csv}_convert.csv')\n",
        "\n",
        "print(f'predict_df_{predict_csv}_convert.csv has been uploaded successfully to the {bucket} bucket')"
      ],
      "metadata": {
        "id": "0venTeG2ztMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88bf6b25-dc59-48ca-aaca-7f1535d53598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict_df_6_convert.csv has been uploaded successfully to the bankmarketingktconverts bucket\n"
          ]
        }
      ]
    }
  ]
}